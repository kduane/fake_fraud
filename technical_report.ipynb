{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sufficient-hepatitis",
   "metadata": {},
   "source": [
    "### Phase 1 - Problem Definition  \n",
    "#### 1.1 Broad Goals  \n",
    "\n",
    "The purpose of this study is to identify fraudulent transactions in an extremely unbalanced dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-activity",
   "metadata": {},
   "source": [
    "#### 1.2 Data Source\n",
    "\n",
    "The data is courtesy of the PaySim synthetic dataset available on Kaggle.  \n",
    "https://www.kaggle.com/ntnu-testimon/paysim1\n",
    "\n",
    "\"PaySim simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company, who is the provider of the mobile financial service which is currently running in more than 14 countries all around the world.\"\n",
    "\n",
    "The kaggle dataset is scaled back to 1/4 the size of the original and simulates 30 days of mobile money transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-hampshire",
   "metadata": {},
   "source": [
    "#### 1.3 Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-buffalo",
   "metadata": {},
   "source": [
    "### Phase 2 - Data Gathering  \n",
    "#### 2.1 Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tutorial-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_auc_score, plot_roc_curve, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-howard",
   "metadata": {},
   "source": [
    "#### 2.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "planned-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')\n",
    "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n",
    "# to make all columns camel case and labeled the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-magic",
   "metadata": {},
   "source": [
    "### Phase 3 - Exploratory Data Analysis  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-satin",
   "metadata": {},
   "source": [
    "    3.1 Dataset Shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facial-henry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-writing",
   "metadata": {},
   "source": [
    "The overall scale of the dataset is 6,362,620 transactions organized by time step\n",
    "\n",
    "The primary takeaways we have from our exploratory data analysis are that some of the included features have little to no bearing on whether a transaction is labeled as fraudulent or not.  Out of the transaction types of 'cash in,' 'cash out,' 'debit,' 'payment,' and 'transfer,' fraudulent transactions are only included in the cash outs and transfers.  \n",
    "\n",
    "When we examine the accounts and account names, we find that the account types of 'merchant' and 'customer' have little connection to which transactions are fraudulent, and in fact are inconsistently applied.  Additionally, only a very few accounts have more than 1 fraudulent transaction either to or from.\n",
    "\n",
    "When we narrow our focus to only the transaction types that contain fraud, a few factors emerge; \n",
    "- the overall number of fraudulent transactions per hour (time step) remain relatively constant despite the total number of all transactions per step being variable.  \n",
    "- the strongest correlations fraudulent activity are in the balance columns of the source and target accounts of the transaction.\n",
    "\n",
    "After exploring this connection further, we start finding that there are errors in both the source accounts and destination accounts.  There are examples where the actual balance of the account money is being transferred to doesn't match the amount transferred.  For example:\n",
    "- The old balance is 0 \n",
    "- The transferred amount is 23.00 \n",
    "- The new balance is 0\n",
    "In this case, we would expect the account balance to be 23.00, when it is instead 0, so our target account variance is  23.00, or $23 of unaccounted for money.\n",
    "\n",
    "This is our best link yet. The errors in the transaction's target account show a clear difference between fraudulent and legitimate transactions. The target account's variance rarely if ever goes negative for fraudulent transactions. In a nutshell, the fraudulent accounts are more likely to have a positive amount of money that is unaccounted for by the recorded transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-custom",
   "metadata": {},
   "source": [
    "    3.2 Fraud by Transaction Type   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "genetic-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.999997\n",
       "1    0.000003\n",
       "Name: isFlaggedFraud, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isFlaggedFraud'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appropriate-receipt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998709\n",
       "1    0.001291\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isFraud'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continental-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type      isFraud\n",
       "CASH_IN   0          1.000000\n",
       "CASH_OUT  0          0.998160\n",
       "          1          0.001840\n",
       "DEBIT     0          1.000000\n",
       "PAYMENT   0          1.000000\n",
       "TRANSFER  0          0.992312\n",
       "          1          0.007688\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by = ['type'])['isFraud'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-closing",
   "metadata": {},
   "source": [
    "At the moment we're ONLY seeing fraud samples in the CASH_OUT and TRANSFER categories.  We might be able to narrow our field of vision to focus on only these two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-fabric",
   "metadata": {},
   "source": [
    "    3.3 Examining Confirmed Fraud Samples   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gorgeous-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['type'] == 'CASH_OUT' ) | (df['type'] == 'TRANSFER')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acoustic-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2762196\n",
       "1       8213\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hidden-swedish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.997035\n",
       "1    0.002965\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isFraud'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-collector",
   "metadata": {},
   "source": [
    "Even in the categories that have confirmed fraud, we're only seeing 8.2k samples of fraud out of 2.7m samples.  Still a highly unbalanced class, although we've improved the positively identified cases from 0.13 % to 0.3 %.  This means that our baseline for our target column will need to be better than 99.7% accurate.  Let's see if we can improve on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legislative-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_or_merch(cell):\n",
    "    if \"M\" in str(cell):\n",
    "        return \"M\"\n",
    "    else:\n",
    "        return \"C\"\n",
    "    \n",
    "df['origAccountType'] = df['nameOrig'].apply(cust_or_merch)\n",
    "df['destAccountType'] = df['nameDest'].apply(cust_or_merch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "flush-local",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    2770409\n",
       "Name: origAccountType, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['origAccountType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "academic-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    1.0\n",
       "Name: destAccountType, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['destAccountType'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-willow",
   "metadata": {},
   "source": [
    "\"M\" type accounts are merchants accounts, originating no transactions and receiving 33.8% of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noted-slovenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destAccountType  isFraud\n",
       "C                0          2762196\n",
       "                 1             8213\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('destAccountType')['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-holiday",
   "metadata": {},
   "source": [
    "And I'm not showing any merchant accounts being confirmed as fraudulent. The merchant prefix of 'M' does not appear to include any examples.  We'll leave this in for now to see if we can spot a correlation once we bring it to the number line, but we might ultimately drop it from the model as so far it seems an irrelevant feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-context",
   "metadata": {},
   "source": [
    "    3.4 Exploring Engineered Features   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-network",
   "metadata": {},
   "source": [
    "Okay, the strongest correlation to fraud is in the oldBalanceOrig column,almost all of the other existing columns are showing very low correlation coefficients. I'll have to try and engineer some features that have stronger coefficients for the model to pick up on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exotic-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['oldBalanceDest']== 0) & (df['newBalanceDest']== 0) & (df['amount'] != 0)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-final",
   "metadata": {},
   "source": [
    "Inspired by observations that there are nearly 6k transactions where the total amount of the origin account is transferred to an empty new account, we tried engineering some features to examine that relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exciting-compact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.995435\n",
       "1    0.004565\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['expectedBalanceDest'] = df['oldBalanceDest'] + df['amount']\n",
    "df[df['expectedBalanceDest'] != df['newBalanceDest']]['isFraud'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "according-easter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.997035\n",
       "1    0.002965\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isFraud'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "durable-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.999951\n",
       "1    0.000049\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['expectedBalanceOrig'] = df['oldBalanceOrig'] - df['amount']\n",
    "df[df['expectedBalanceOrig'] != df['newBalanceOrig']]['isFraud'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-packing",
   "metadata": {},
   "source": [
    "The pattern we start to see is in the accounts where the expected balance and the actual balance post transaction do not line up. For example:  \n",
    "    - The old balance is 0\n",
    "    - The transferred amount is 23.00\n",
    "    - The new balance is 0\n",
    "\n",
    "In this case, we would expect the account balance to be 23.00, when it is instead 0, so our target account variance is + 23.00, or $23 of unaccounted for money.\n",
    "\n",
    "We'll also apply this test to the origin or source account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "residential-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior balance of target account + amount transferred - new balance of target account\n",
    "df['tarDiff'] = df['oldBalanceDest'] + df['amount'] - df['newBalanceDest']\n",
    "# and for good measure, let's apply the test to the source account as well\n",
    "# prior balance of source account + amount transferred - new balance of source account\n",
    "df['sourceDiff'] = df['newBalanceOrig'] + df['amount'] - df['oldBalanceOrig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'tarDiff',y = 'step', hue = 'isFraud', data = df )\n",
    "plt.title('Destination Account Balance Variance from Expected')\n",
    "plt.savefig('./imgs/tarAccountVariance.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-titanium",
   "metadata": {},
   "source": [
    "After trying several different visualizations, we get our clearest difference so far.  The errors in the transfer's target account show a clear difference between fraudulent and legitimate transactions.  The target account's variance rarely if ever goes negative for fraudulent transactions. In a nutshell, the fraudulent accounts are more likely to have a positive amount of money that is unaccounted for by the recorded transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-database",
   "metadata": {},
   "source": [
    "    3.5 Correllation to Fraud   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA indicated 3 columns were irrelevant:\n",
    "\n",
    "df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr()[['isFraud']].sort_values(by = 'isFraud', ascending = False),\n",
    "            vmin = -1,\n",
    "            vmax = 1,\n",
    "            cmap = 'viridis',\n",
    "            annot = True)\n",
    "plt.title('Correlation Heatmap of All Categories Including Engineered Features')\n",
    "plt.savefig('./imgs/correlationHeatmap.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df['isFraud']== 1]\n",
    "mask = np.zeros_like(fraud.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    f, ax = plt.subplots(figsize = (10, 10))\n",
    "    ax = sns.heatmap(fraud.corr(), \n",
    "                     mask = mask, \n",
    "                     vmin = -1, \n",
    "                     vmax = 1, \n",
    "                     square = True, \n",
    "                     cmap = 'viridis', \n",
    "                     annot = True,\n",
    "                     cbar = False)\n",
    "    plt.title(\"Fraudulent Transactions\")\n",
    "    plt.savefig('./imgs/fraud_corr_heatmap.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "notFraud= df[df['isFraud']== 0]\n",
    "mask = np.zeros_like(notFraud.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    f, ax = plt.subplots(figsize = (10, 10))\n",
    "    ax = sns.heatmap(notFraud.corr(),\n",
    "                     mask = mask, \n",
    "                     vmin = -1, \n",
    "                     vmax = 1, \n",
    "                     square = True, \n",
    "                     cmap = 'viridis', \n",
    "                     annot = True,\n",
    "                     cbar = False)\n",
    "    plt.title(\"Legitimate Transactions\")\n",
    "    plt.savefig('./imgs/not_fraud_corr_heatmap.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-dialogue",
   "metadata": {},
   "source": [
    "Comparing the correlation heatmaps of the two main categories of fraudulent and legitimate transactions, we can see a clear differences in the corrlations of the expected balances and balance variances between the two categories.  This confirms we're on the right path and that we'll have patterns our model will be able to pick up on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-patrol",
   "metadata": {},
   "source": [
    "### Phase 4 - Modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-silicon",
   "metadata": {},
   "source": [
    "    4.1 Load a fresh copy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-ukraine",
   "metadata": {},
   "source": [
    "    4.2 Clean, transform, and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make all columns camel case and labeled the same way\n",
    "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n",
    "\n",
    "# EDA indicated 3 columns were irrelevant:\n",
    "\n",
    "df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)\n",
    "\n",
    "# EDA indicated fraudulent transactions only occur in CASH_OUT and TRANSFER types\n",
    "\n",
    "df = df[(df['type'] == 'CASH_OUT' ) | (df['type'] == 'TRANSFER')]\n",
    "\n",
    "# engineered columns \n",
    "df['sourceBalanceDiff'] = df['newBalanceOrig'] + df['amount'] - df['oldBalanceOrig']\n",
    "df['tarBalanceDiff'] = df['oldBalanceDest'] + df['amount'] - df['newBalanceDest']\n",
    "\n",
    "# bringing all categories to the number line\n",
    "df = pd.get_dummies(columns = ['type'], drop_first = True, data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-youth",
   "metadata": {},
   "source": [
    "    4.3 Train/Test/Split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify = y)\n",
    "ss = StandardScaler()\n",
    "Z_train = ss.fit_transform(X_train)\n",
    "Z_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-sender",
   "metadata": {},
   "source": [
    "    4.4 Methods for Handling Imbalanced Classes   \n",
    "        - oversampling   \n",
    "        - undersampling  \n",
    "        - SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-wealth",
   "metadata": {},
   "source": [
    "Because we're dealing with a highly skewed and imbalanced dataset, my different modeling notebooks explored different methods of handling imbalanced data, including oversampling, undersampling, and the SMOTE technique.  Interestingly, the best results were with the core unaltered dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-steering",
   "metadata": {},
   "source": [
    "    4.5 Model Selection\n",
    "    \n",
    "After several trials, the model that performs the best is the Random Forest Classifier, a model type that excels with handling imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-rover",
   "metadata": {},
   "source": [
    "    4.6 Random Forest Classifier - Best Parameters   \n",
    "    \n",
    "Gridsearching and tuning the random forest resulted in a model that is 99.9987% accurate, with a total of 8 misclassifications in the 692,603 reserved testing samples.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')\n",
    "rfc.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-grammar",
   "metadata": {},
   "source": [
    "### Phase 5 - Model Analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-pitch",
   "metadata": {},
   "source": [
    "    5.0 Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-reading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "healthy-thumbnail",
   "metadata": {},
   "source": [
    "    5.1 Compare Accuracy Scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-canvas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "verified-california",
   "metadata": {},
   "source": [
    "    5.2 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-yahoo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addressed-sphere",
   "metadata": {},
   "source": [
    "### Phase 6 - Conclusions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-fiction",
   "metadata": {},
   "source": [
    "    6.1 Revisit 1.3 Problem Statement  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-purpose",
   "metadata": {},
   "source": [
    "    6.2 Conclusions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-bracelet",
   "metadata": {},
   "source": [
    "    6.3 Recommendations for Further Research "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-aside",
   "metadata": {},
   "source": [
    "###  Acknowledgements\n",
    "\n",
    "PaySim first paper of the simulator:\n",
    "\n",
    "E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016\n",
    "\n",
    "Engineered error columns inspired by Joshua Arjun's award winning kaggle notebook:\n",
    "https://www.kaggle.com/arjunjoshua/predicting-fraud-in-financial-payment-services?rvi=1&scriptVersionId=2200418&cellId=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-outline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit (conda)",
   "language": "python",
   "name": "python37764bitconda77dc9d652bc147c6a9d0ea8af6b5ba0e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
