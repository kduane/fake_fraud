{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_auc_score, plot_roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1 Loading and Cleaning the Data for Comparative Modeling\n",
    "\n",
    "df = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')\n",
    "\n",
    "# to make all columns camel case and labeled the same way\n",
    "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n",
    "\n",
    "# EDA indicated 3 columns were irrelevant:\n",
    "\n",
    "df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)\n",
    "\n",
    "# EDA indicated fraudulent transactions only occur in CASH_OUT and TRANSFER types\n",
    "\n",
    "df = df[(df['type'] == 'CASH_OUT' ) | (df['type'] == 'TRANSFER')]\n",
    "\n",
    "#engineered columns \n",
    "df['sourceBalanceDiff'] = df['newBalanceOrig'] + df['amount'] - df['oldBalanceOrig']\n",
    "df['tarBalanceDiff'] = df['oldBalanceDest'] + df['amount'] - df['newBalanceDest']\n",
    "\n",
    "df = pd.get_dummies(columns = ['type'], drop_first = True, data = df)\n",
    "\n",
    "X = df.drop(columns = ['isFraud'])\n",
    "y = df['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify = y)\n",
    "over = SMOTE(sampling_strategy = 0.1)\n",
    "X1_train, y1_train = over.fit_resample(X_train, y_train)\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy = 0.5)\n",
    "X2_train, y2_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "steps = [('o', over), ('u', under)]\n",
    "balance_pipe = Pipeline(steps = steps)\n",
    "X3_train, y3_train = balance_pipe.fit_resample(X_train, y_train)\n",
    "\n",
    "D_train = xgb.DMatrix(X_train, label = y_train)\n",
    "D_test = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "D1_train = xgb.DMatrix(X1_train, label = y1_train)\n",
    "D1_test = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "D2_train = xgb.DMatrix(X2_train, label = y2_train)\n",
    "D2_test = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "D3_train = xgb.DMatrix(X3_train, label = y3_train)\n",
    "D3_test = xgb.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Unaltered\" : [D_train, D_test],\n",
    "    \"Oversampled Minority\" : [D1_train, D1_train],\n",
    "    \"Undersample Majority\" : [D2_train, D2_train],\n",
    "    \"Balanced SMOTE\" : [D3_train, D3_train]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[14:47:27] ../src/objective/regression_obj.cu:57: Check failed: preds.Size() == info.labels_.Size() (4155612 vs. 2077806) :  labels are not correctly providedpreds.size=4155612, label.size=2077806, Loss: binary:logistic\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000011c7d88be dmlc::LogMessageFatal::~LogMessageFatal() + 110\n  [bt] (1) 2   libxgboost.dylib                    0x000000011c8dfcbf xgboost::obj::RegLossObj<xgboost::obj::LogisticClassification>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*) + 447\n  [bt] (2) 3   libxgboost.dylib                    0x000000011c889ca1 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 609\n  [bt] (3) 4   libxgboost.dylib                    0x000000011c7dd4dc XGBoosterUpdateOneIter + 156\n  [bt] (4) 5   libffi.7.dylib                      0x00000001061e6ead ffi_call_unix64 + 85\n  [bt] (5) 6   ???                                 0x00007ffeea5365b0 0x0 + 140732829754800\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0396bd354e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [14:47:27] ../src/objective/regression_obj.cu:57: Check failed: preds.Size() == info.labels_.Size() (4155612 vs. 2077806) :  labels are not correctly providedpreds.size=4155612, label.size=2077806, Loss: binary:logistic\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000011c7d88be dmlc::LogMessageFatal::~LogMessageFatal() + 110\n  [bt] (1) 2   libxgboost.dylib                    0x000000011c8dfcbf xgboost::obj::RegLossObj<xgboost::obj::LogisticClassification>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*) + 447\n  [bt] (2) 3   libxgboost.dylib                    0x000000011c889ca1 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 609\n  [bt] (3) 4   libxgboost.dylib                    0x000000011c7dd4dc XGBoosterUpdateOneIter + 156\n  [bt] (4) 5   libffi.7.dylib                      0x00000001061e6ead ffi_call_unix64 + 85\n  [bt] (5) 6   ???                                 0x00007ffeea5365b0 0x0 + 140732829754800\n\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 4, figsize = (20, 5), sharey = 'row')\n",
    "\n",
    "models = []\n",
    "\n",
    "for i, (key, dataset) in enumerate(datasets.items()):\n",
    "    params = {\n",
    "        'eta' : 0.3,\n",
    "        'max_depth': 5, \n",
    "        'objective' : 'binary:logistic',\n",
    "        'num_class': 2\n",
    "    }\n",
    "    steps = 20\n",
    "    \n",
    "    model = xgb.train(params, dataset[0], steps)\n",
    "    y_pred = model.predict(dataset[1])\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cf_matrix)\n",
    "    disp.plot(ax = axes[i])\n",
    "    disp.ax_.set_title(key)\n",
    "    disp.im_.colorbar.remove()\n",
    "    if i != 0:\n",
    "        disp.ax_.set_ylabel('')\n",
    "    \n",
    "    model_dict = {key: model, 'preds': y_pred, 'Confusion Matrix': cf_matrix}\n",
    "    models.append(model_dict)\n",
    "        \n",
    "f.text(0.4, 0.1, 'Predicted Label', ha = 'left')\n",
    "f.colorbar(disp.im_, ax = axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit (conda)",
   "language": "python",
   "name": "python37764bitconda77dc9d652bc147c6a9d0ea8af6b5ba0e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
